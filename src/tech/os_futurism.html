<!DOCTYPE html>
<html lang="en">
<head>
    <title>Operating System Futurism</title>
<!--    connected with UX user interaction design -->
    <!--suppress CheckEmptyScriptTag -->
    <include src="/fragment/head.html" />
</head>
<body>

<!--suppress CheckEmptyScriptTag -->
<include src="/fragment/nav.html" />

<main>
    Where are new UI/UX paradigms being explored in the Linux ecosystem? So much looks and feels like everything other desktop environment. I have a hard time believing that we've reached the ultimate best visual metaphor for computing already.
    The only thing I've found that seems to break new ground is the i3wm tiling window manager.

    I'll just throw out a couple ideas:
    <ul>
    <li>Why do click targets need to remain constant in size? Fitts' law tells us that we hit a target faster when it's harder. We could resize click targets (ie window close button) based on context or keyboard action.
    <li>Flat rectangles are a design constraint imposed mainly by low resolution displays. What designs could we unlock with a HiDPI-native desktop environment? (That being said... the notch proves that developers hate anything non-rectangular.)
    <li>imagine a web browser that flowed content into the available space, even if it wasn't rectangular. So if you stacked another window over top the browser, no content would be obscured.
    <li>Monitors are getting much wider, extending into our peripheral vision. We should be treating the focal area differently from the peripheral area.
    <li>Virtual desktops are currently implemented as "modes" to be transitioned between. What about making one large canvas, of which only a cropped portion is rendered to a monitor, and the viewed area could be moved?
    <li>most Video game environments (excluding Eve) don't look like a traditional DE/WM.  What can we learn from them about presenting and processing a lot of information?
    <li>Do we need window chrome (close button) at all, or can we get by with a combination of keyboard actions and gestures?
    <li>The interaction metaphor should be informed by how we work -- if we are often interrupted, how can the environment help us process those interruptions and resume our prior state with minimal friction?
    <li>What aspects of a command line make it powerful? In my opinion, theres something very important about telling the computer exactly what you want without having to pick from a menu of options. It's about intent, not distraction.
    <li>The "reader view" in a browser dramatically transforms the content, temporarily. What would that look like outside of a browser?
    <li>The desktop metaphor was invented before persistent connectivity. Now we have information always arriving that we didn't put there. How might we have designed this differently from first principles?
    </ul>

    <!--
    Found a blog post https://uxdesign.cc/the-desktop-metaphor-must-die-676fbb34afdb
    This is a cute retrospective, but offers no new ideas. http://continentcontinent.cc/index.php/continent/article/view/334
    -->

    https://djrobstep.com/posts/programs-are-a-prison

    https://julian.digital/2020/09/04/a-meta-layer-for-notes/

<!--    Do I need a page about shell? -->
    https://zaiste.net/posts/shell-commands-rust/

    https://www.marceltheshell.org/functions-1

    https://www.divergent-desktop.org/blog/2020/08/10/principles-overview/

    https://uxdesign.cc/introducing-mercury-os-f4de45a04289
    via https://news.ycombinator.com/item?id=24783387

    http://www.projectoberon.com
    via https://news.ycombinator.com/item?id=24468704

</main>

<!--suppress CheckEmptyScriptTag -->
<include src="/fragment/footer.html" />
</body>
</html>
